[2024-07-19 22:20:31,333][avhubert.hubert_pretraining][INFO] - current directory is D:\LipReading\Lip2SpeechUnit\lip2speech-unit\multi_target_lip2speech\outputs\2024-07-19\22-20-28
[2024-07-19 22:20:31,337][avhubert.hubert_pretraining][INFO] - AVHubertPretrainingTask Config {'_name': 'lip2speech', 'data': '/home/js/lip2speech-unit/datasets/lrs3/label', 'labels': ['unt'], 'label_dir': '/home/js/lip2speech-unit/datasets/lrs3/label', 'label_rate': 50, 'sample_rate': 25, 'normalize': True, 'enable_padding': False, 'max_sample_size': 600, 'min_sample_size': None, 'max_trim_sample_size': '${task.max_sample_size}', 'single_target': True, 'random_crop': False, 'pad_audio': True, 'pdb': False, 'stack_order_audio': 4, 'skip_verify': False, 'image_aug': True, 'image_crop_size': 88, 'image_mean': 0.421, 'image_std': 0.165, 'modalities': ['video'], 'is_s2s': False, 'tokenizer_bpe_name': None, 'tokenizer_bpe_model': None, 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': '0', 'noise_num': 1, 'fine_tuning': True, 'time_mask': True, 'random_erase': True}
[2024-07-19 22:20:33,658][avhubert.hubert_pretraining][INFO] - current directory is D:\LipReading\Lip2SpeechUnit\lip2speech-unit\multi_target_lip2speech\outputs\2024-07-19\22-20-28
[2024-07-19 22:20:33,660][avhubert.hubert_pretraining][INFO] - AVHubertPretrainingTask Config {'_name': 'lip2speech', 'data': '/home/js/lip2speech-unit/datasets/lrs3/label', 'labels': ['unt'], 'label_dir': '/home/js/lip2speech-unit/datasets/lrs3/label', 'label_rate': 50, 'sample_rate': 25, 'normalize': True, 'enable_padding': False, 'max_sample_size': 600, 'min_sample_size': None, 'max_trim_sample_size': '${task.max_sample_size}', 'single_target': True, 'random_crop': False, 'pad_audio': True, 'pdb': False, 'stack_order_audio': 4, 'skip_verify': False, 'image_aug': True, 'image_crop_size': 88, 'image_mean': 0.421, 'image_std': 0.165, 'modalities': ['video'], 'is_s2s': False, 'tokenizer_bpe_name': None, 'tokenizer_bpe_model': None, 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': '0', 'noise_num': 1, 'fine_tuning': True, 'time_mask': True, 'random_erase': True}
[2024-07-19 22:20:33,662][hybrid.speech_recognize][INFO] - {'_name': None, 'task': None, 'generation': {'_name': None, 'beam': 50, 'nbest': 1, 'max_len_a': 1.0, 'max_len_b': 0, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': 'D:/LipReading/Lip2SpeechUnit/lip2speech-unit/multi_target_lip2speech', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'D:/LipReading/Lip2SpeechUnit/lip2speech-unit/multi_target_lip2speech/checkpoints/lip2speech_lrs3_multi.pt', 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': 'D:/LipReading/Lip2SpeechUnit/lip2speech-unit/multi_target_lip2speech/results'}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 1000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 1000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'override': {'_name': None, 'noise_wav': None, 'noise_prob': 0.0, 'noise_snr': 0.0, 'modalities': ['video'], 'data': None, 'label_dir': None}, 'is_ax': False}
[2024-07-19 22:20:33,722][avhubert.hubert_dataset][INFO] - max_keep=600, min_keep=None, loaded 5, skipped 0 short and 0 long and 0 unaligned, longest-loaded=107, shortest-loaded=31
[2024-07-19 22:20:33,725][multi_target_lip2speech.dataset][INFO] - image transform: Compose(
    Normalize(mean=0.0, std=255.0)
    <multi_target_lip2speech.utils_aug.CenterCrop object at 0x000002EA30EA54B0>
    Normalize(mean=0.421, std=0.165)
)
[2024-07-19 22:20:33,726][multi_target_lip2speech.dataset][INFO] - pad_audio=True, random_crop=False, normalize=True, max_sample_size=600, seqs2seq data=False,
[2024-07-19 22:20:33,727][multi_target_lip2speech.dataset][INFO] - Noise wav: None->0 wav, Prob: 0.0, SNR: 0.0, Number of mixture: 1
[2024-07-19 22:20:46,275][hybrid.speech_recognize][INFO] - 
REF:14 14 14 131 131 42 11 11 125 89 31 46 46 46 170 170 170 95 95 71 30 30 120 120 62 71 44 44 41 160 160 160 17 17 17 66 71 162 161 161 161 42 42 11 125 122 23 23 56 56 35 35 35 126 126 87 87 157 157 0 0 133 133 133 10 156 44 44 115 115 143 104 104 153 193 193 190 190 169 169 33 136 136 9 9 30 71 89 31 48 48 21 130 130 130 128 128 128 26 26 147 147 82 75 75 75 75 139 36 36 125 162 166 166 42 42 11 125 125 122 122 176 4 4 4 4 150 3 81 81 81 83 83 83 83 155 155 53 53 53 53 53 106 139 139 139 84 84 84 133 133 133 10 10 10 10 121 104 59 187 187 187 151 111 111 180 180 180 48 0 133 133 133 122 111 141 141 141 102 102 180 180 15 178 178 169 105 105 105 105 148 148 148 148 148 148 148 148 148 148 78 78 78 40 40 67 67 67 67 67 67 152 92 92
HYP:14 14 14 131 131 11 11 22 22 10 31 31 46 46 46 170 170 170 95 78 30 30 180 180 180 62 15 41 115 115 95 95 158 158 158 158 99 99 99 99 99 99 97 97 97 97 97 97 108 108 35 35 35 126 87 87 157 157 0 0 133 133 133 133 133 156 44 44 115 143 143 104 104 104 193 190 190 190 169 169 169 136 136 79 79 71 30 30 129 129 48 21 130 130 128 128 60 26 47 147 147 147 75 139 139 139 197 197 197 8 8 8 8 8 8 8 8 8 86 86 122 122 103 103 103 4 4 4 3 81 81 81 5 5 83 26 147 53 53 53 53 53 139 139 139 133 133 133 133 133 133 133 10 10 10 121 121 59 59 187 187 187 151 111 111 180 180 180 180 152 152 133 133 133 133 122 180 180 180 180 180 180 62 62 62 62 44 193 193 99 148 148 148 148 148 148 148 148 148 148 78 78 78 70 40 195 67 171 67 67 67 67 152 92

[2024-07-19 22:20:46,332][hybrid.speech_recognize][INFO] - 
REF:4 14 14 14 11 131 131 125 125 57 57 18 18 25 82 114 7 194 194 198 198 198 198 198 32 32 36 162 162 166 42 42 42 133 122 122 122 120 120 120 48 74 74 125 73 73 186 186 186 164 164 95 71 34 158 119 119 82 63 182 134 134 169 105 105 97 108 148 108 184 160 17 93 66 146 116 116 116 172 185 171 171 171 48 6 41 151 126 87 87 168 175 175 175 43 43 91 91 65 65 126 87 48 74 156 156 156 73 145 145 145 108 108 184 101 183 183 183 183 3 3 144 144 198 28 28 190 190 45 33 9 13 85 125 154 154 46 96 198 198 12 123 85 125 73 45 45 45 169 9 9 23 23 23 142 148 148 148 148 148 35 35 126 87 87 180 62 59 59 26 26 26 26 53 75 139 139 92
HYP:14 14 14 131 11 11 125 110 110 18 18 18 25 25 25 25 25 63 63 63 75 139 139 139 70 133 133 133 133 133 133 133 122 122 122 120 120 120 120 48 74 74 74 73 73 186 186 186 164 95 71 71 34 158 119 51 51 63 134 134 134 105 105 105 72 72 72 72 160 160 17 17 21 130 128 116 116 172 172 195 171 171 98 98 151 151 126 87 87 157 48 74 74 146 146 3 3 91 91 91 91 65 13 156 156 73 145 145 145 145 108 108 184 183 183 183 183 183 3 3 144 144 28 28 190 190 45 45 9 9 85 85 89 154 154 96 96 198 12 12 85 71 73 73 45 45 45 9 9 23 23 23 23 148 148 148 148 148 35 35 78 111 111 141 141 102 15 15 41 5 5 53 53 53 93 66 121 59

[2024-07-19 22:20:46,346][hybrid.speech_recognize][INFO] - 
REF:14 14 14 131 11 125 125 22 22 125 34 158 46 46 193 148 148 148 88 155 155 155 126 87 157 171 98 165 173 173 45 45 45 9 9 111 19 19 120 120 120 74 74 125 125 73 144 144 144 198 198 198 198 198 123 123 123 195 195 171 98 0 0 57 113 151 151 126 111 141 102 102 15 41 5 53 53 112 66 59 136 119 51 17 66 89 196 196 196 80 130 128 128 145 108 108 184 184 163 163 70 70 156 156 44 187 187 187 176 176 176 4 4 109 109 81 26 26 26 26 75 139 92 92
HYP:14 14 14 131 131 11 22 86 86 34 158 193 193 148 148 148 148 148 78 140 71 195 195 171 150 150 150 45 45 45 45 33 9 9 9 141 141 120 120 74 74 74 89 73 144 144 144 198 198 198 198 198 198 12 123 195 195 171 171 98 98 98 119 198 37 63 112 168 168 102 15 41 5 5 53 93 66 121 59 160 160 17 17 66 66 196 196 196 128 128 128 145 108 108 184 184 184 70 70 70 70 89 44 44 187 187 187 176 176 176 103 4 4 109 3 119 1 1 1 75 75 70 70 70

[2024-07-19 22:20:46,361][hybrid.speech_recognize][INFO] - 
REF:92 14 14 14 14 86 86 86 110 145 145 108 184 95 71 125 34 158 113 113 172 185 182 182 177 106 193 49 49 159 95 71 71 71 89 59 193 193 170 35 35 95 71 71 125 44 44 151 151 111 111 141 102 102 15 41 187 187 187 187 126 40 67 171 98 98 119 1 75 75 139 139 133 133
HYP:14 14 14 131 131 131 110 110 145 145 184 184 82 135 7 7 16 16 186 164 21 21 130 128 116 49 49 159 184 71 71 71 89 59 193 193 56 148 35 69 69 127 127 115 95 95 34 34 141 141 150 150 150 3 81 81 187 172 172 40 195 67 171 98 98 98 28 28 16 75 179 179 179 179

[2024-07-19 22:20:46,375][hybrid.speech_recognize][INFO] - 
REF:14 14 171 171 120 48 48 125 153 193 193 170 78 78 71 71 19 48 48 48 128 128 116 163 163 70 125 31 31 46 46 46 170 170 95 95 30 30 19 120 62 125 44 58 58 160 160 17 17 158 113 28 113 151 126 126 87 157 62 74 135 135
HYP:12 172 195 195 171 98 98 143 121 59 56 56 35 35 111 168 19 48 48 183 183 3 144 181 181 181 38 54 169 169 105 105 145 108 108 184 184 126 87 157 62 62 59 59 144 144 144 198 198 158 99 113 187 1 151 126 126 87 157 157 152 36

[2024-07-19 22:20:46,391][hybrid.speech_recognize][INFO] - NOTE: hypothesis and token scores are output in base 2
[2024-07-19 22:20:46,393][hybrid.speech_recognize][INFO] - Recognized 5 utterances (657 tokens) in 9.4s (0.53 sentences/s, 69.86 tokens/s)
[2024-07-19 22:20:46,420][hybrid.speech_recognize][INFO] - WER: 56.13496932515337%
[2024-07-19 22:20:46,421][hybrid.speech_recognize][INFO] - Accuracy: 28.220858895705522%
